{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Mohammed errakho - adil oussidi**","metadata":{}},{"cell_type":"code","source":"# pandas and numpy for data manipulation.\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom matplotlib.pyplot import imshow","metadata":{"execution":{"iopub.status.busy":"2022-01-19T15:10:06.086055Z","iopub.execute_input":"2022-01-19T15:10:06.086468Z","iopub.status.idle":"2022-01-19T15:10:06.118944Z","shell.execute_reply.started":"2022-01-19T15:10:06.086358Z","shell.execute_reply":"2022-01-19T15:10:06.117901Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# tenserflow imports.\nimport tensorflow as tf\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2022-01-19T15:11:44.465313Z","iopub.execute_input":"2022-01-19T15:11:44.465688Z","iopub.status.idle":"2022-01-19T15:11:51.542684Z","shell.execute_reply.started":"2022-01-19T15:11:44.465639Z","shell.execute_reply":"2022-01-19T15:11:51.541937Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"Data = pd.read_csv(\"../input/hand-gesture-recognition-2nd-edition/train.csv\")\nTest = pd.read_csv(\"/kaggle/input/hand-gesture-recognition-2nd-edition/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-01-19T15:15:35.910022Z","iopub.execute_input":"2022-01-19T15:15:35.910395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reshape():\n    images = np.zeros((len(Data),211,271))\n    for i in range(len(Data)):\n        im_buf = Data.values[i][2:] # create flat array of only the pixels of the given image \n        images[i] = np.reshape(im_buf, (211, 271)) # create a 2D array from flat array\n    if (i+1)%1000==0:\n        pass\n        #print(i)\n    return True","metadata":{"execution":{"iopub.status.busy":"2021-12-09T20:41:36.794069Z","iopub.execute_input":"2021-12-09T20:41:36.794359Z","iopub.status.idle":"2021-12-09T20:41:38.669637Z","shell.execute_reply.started":"2021-12-09T20:41:36.794329Z","shell.execute_reply":"2021-12-09T20:41:38.668785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reshape()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Model():\n    inputs = keras.Input(shape=(211, 271, 1))\n    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n    x = layers.MaxPooling2D(pool_size=2)(x)\n    x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPooling2D(pool_size=2)(x)\n    x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n    x = layers.Flatten()(x)\n    outputs = layers.Dense(16, activation=\"softmax\")(x)\n    model = keras.Model(inputs=inputs, outputs=outputs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-09T20:44:00.099163Z","iopub.execute_input":"2021-12-09T20:44:00.099668Z","iopub.status.idle":"2021-12-09T20:44:00.190241Z","shell.execute_reply.started":"2021-12-09T20:44:00.099632Z","shell.execute_reply":"2021-12-09T20:44:00.189579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = np.array(Data['label'])-1\nn_values = np.max(labels) + 1\ntargets = np.eye(n_values)[labels]\n\n# returning the model\nmodel = Model()\n\n# compiling the model\nmodel.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\nmodel.fit(x = images, y = targets, epochs = 8, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T20:44:05.98135Z","iopub.execute_input":"2021-12-09T20:44:05.981655Z","iopub.status.idle":"2021-12-09T20:58:38.4788Z","shell.execute_reply.started":"2021-12-09T20:44:05.981625Z","shell.execute_reply":"2021-12-09T20:58:38.478137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test = model.predict(images_t)\ny_test = np.argmax(y_test,1)\ny_test +=1","metadata":{"execution":{"iopub.status.busy":"2021-12-09T20:58:46.582128Z","iopub.execute_input":"2021-12-09T20:58:46.58246Z","iopub.status.idle":"2021-12-09T20:58:55.02836Z","shell.execute_reply.started":"2021-12-09T20:58:46.582423Z","shell.execute_reply":"2021-12-09T20:58:55.02767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preparing the submission file.\nsample = pd.read_csv(\"../input/hand-gesture-recognition-2nd-edition/sample_submission.csv\")\nsubmission = pd.DataFrame({'id':Test.id,'label':y_test})\nsubmission.to_csv('submission2.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-09T20:59:16.290759Z","iopub.execute_input":"2021-12-09T20:59:16.291835Z","iopub.status.idle":"2021-12-09T20:59:16.300756Z","shell.execute_reply.started":"2021-12-09T20:59:16.291775Z","shell.execute_reply":"2021-12-09T20:59:16.299901Z"},"trusted":true},"execution_count":null,"outputs":[]}]}